#!/bin/bash

# DataHawk - Script para Download de Modelos LLM Recomendados
# Baixa modelos otimizados para baixo consumo de RAM

set -e

MODELS_DIR="models"
TEMP_DIR="/tmp/datahawk-models"

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}ðŸš€ DataHawk - Download de Modelos LLM Recomendados${NC}"
echo "=================================================="

# Criar diretÃ³rios
mkdir -p "$MODELS_DIR"
mkdir -p "$TEMP_DIR"

# FunÃ§Ã£o para verificar espaÃ§o em disco
check_disk_space() {
    local required_gb=$1
    local available_gb=$(df . | tail -1 | awk '{print int($4/1024/1024)}')

    if [ "$available_gb" -lt "$required_gb" ]; then
        echo -e "${RED}âŒ EspaÃ§o insuficiente: ${available_gb}GB disponÃ­vel, ${required_gb}GB necessÃ¡rio${NC}"
        return 1
    fi

    echo -e "${GREEN}âœ… EspaÃ§o suficiente: ${available_gb}GB disponÃ­vel${NC}"
    return 0
}

# FunÃ§Ã£o para baixar modelo
download_model() {
    local name=$1
    local url=$2
    local filename=$3
    local size=$4

    echo -e "\n${YELLOW}ðŸ“¦ Baixando: ${name} (${size})${NC}"
    echo "URL: $url"

    if [ -f "$MODELS_DIR/$filename" ]; then
        echo -e "${GREEN}âœ… Modelo jÃ¡ existe: $filename${NC}"
        return 0
    fi

    # Baixar para diretÃ³rio temporÃ¡rio primeiro
    echo "Baixando para $TEMP_DIR/$filename..."
    if wget -q --show-progress --timeout=30 --tries=3 "$url" -O "$TEMP_DIR/$filename"; then
        # Verificar se o arquivo foi baixado corretamente
        if [ -s "$TEMP_DIR/$filename" ]; then
            # Mover para diretÃ³rio final apenas se download completo
            mv "$TEMP_DIR/$filename" "$MODELS_DIR/$filename"
            echo -e "${GREEN}âœ… Download concluÃ­do: $filename${NC}"
            return 0
        else
            echo -e "${RED}âŒ Arquivo baixado estÃ¡ vazio: $filename${NC}"
            rm -f "$TEMP_DIR/$filename"
            return 1
        fi
    else
        echo -e "${RED}âŒ Falha no download: $filename${NC}"
        rm -f "$TEMP_DIR/$filename"
        return 1
    fi
}

# Verificar se wget estÃ¡ instalado
if ! command -v wget &> /dev/null; then
    echo -e "${RED}âŒ wget nÃ£o encontrado. Instale com: sudo apt install wget${NC}"
    exit 1
fi

echo -e "\n${BLUE}ðŸ’¾ Verificando espaÃ§o em disco...${NC}"
if ! check_disk_space 10; then
    echo -e "${RED}âŒ Pelo menos 10GB de espaÃ§o livre sÃ£o necessÃ¡rios${NC}"
    exit 1
fi

echo -e "\n${BLUE}ðŸ“‹ Modelos disponÃ­veis:${NC}"
echo "1. TinyLlama 1.1B Chat (~0.8GB) - Ultra rÃ¡pido"
echo "2. Qwen 1.5 1.8B Chat (~1.2GB) - Bom raciocÃ­nio"
echo "3. Gemma 2B IT (~1.5GB) - Equilibrado, bom PT-BR"
echo "4. Phi-3 Mini 4K (~2.7GB) - Qualidade superior"
echo "5. Todos os modelos acima"

echo -e "\n${YELLOW}Escolha uma opÃ§Ã£o (1-5):${NC}"
read -r choice

case $choice in
    1)
        echo -e "\n${BLUE}Baixando TinyLlama 1.1B Chat...${NC}"
        download_model \
            "TinyLlama 1.1B Chat" \
            "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf" \
            "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf" \
            "0.8GB"
        ;;
    2)
        echo -e "\n${BLUE}Baixando Qwen 1.5 1.8B Chat...${NC}"
        download_model \
            "Qwen 1.5 1.8B Chat" \
            "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q4_k_m.gguf" \
            "qwen1.5-1.8b-chat.Q4_K_M.gguf" \
            "1.2GB"
        ;;
    3)
        echo -e "\n${BLUE}Baixando Gemma 2B IT...${NC}"
        download_model \
            "Gemma 2B IT" \
            "https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF/resolve/main/gemma-2b-it-q4_k_m.gguf" \
            "gemma-2b-it.Q4_K_M.gguf" \
            "1.5GB"
        ;;
    4)
        echo -e "\n${BLUE}Baixando Phi-3 Mini 4K...${NC}"
        download_model \
            "Phi-3 Mini 4K" \
            "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf" \
            "phi-3-mini-4k-instruct.Q4_K_M.gguf" \
            "2.7GB"
        ;;
    5)
        echo -e "\n${BLUE}Baixando todos os modelos...${NC}"

        download_model \
            "TinyLlama 1.1B Chat" \
            "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf" \
            "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf" \
            "0.8GB"

        download_model \
            "Qwen 1.5 1.8B Chat" \
            "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q4_k_m.gguf" \
            "qwen1.5-1.8b-chat.Q4_K_M.gguf" \
            "1.2GB"

        download_model \
            "Gemma 2B IT" \
            "https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF/resolve/main/gemma-2b-it-q4_k_m.gguf" \
            "gemma-2b-it.Q4_K_M.gguf" \
            "1.5GB"

        download_model \
            "Phi-3 Mini 4K" \
            "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf" \
            "phi-3-mini-4k-instruct.Q4_K_M.gguf" \
            "2.7GB"
        ;;
    *)
        echo -e "${RED}âŒ OpÃ§Ã£o invÃ¡lida${NC}"
        exit 1
        ;;
esac

# Limpeza
rm -rf "$TEMP_DIR"

echo -e "\n${GREEN}âœ… Download(s) concluÃ­do(s)!${NC}"
echo -e "\n${BLUE}ðŸ“‚ Modelos disponÃ­veis em $MODELS_DIR/:${NC}"
ls -lah "$MODELS_DIR"/*.gguf 2>/dev/null || echo "Nenhum modelo encontrado"

echo -e "\n${BLUE}ðŸš€ Para usar o servidor LLM:${NC}"
echo "python3 llm-server-production.py"

echo -e "\n${BLUE}ðŸ’¡ Dicas:${NC}"
echo "â€¢ TinyLlama: Ideal para RAM <= 4GB"
echo "â€¢ Qwen 1.8B: Bom para cÃ¡lculos simples"
echo "â€¢ Gemma 2B: Melhor para portuguÃªs"
echo "â€¢ Phi-3 Mini: Qualidade superior geral"
