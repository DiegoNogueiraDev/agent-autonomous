# BUG-001: Servidor LLM perde conexão durante validação

## 📋 Informações Básicas
- **ID:** BUG-001
- **Data:** 2025-07-21
- **Severidade:** High
- **Status:** Open

## 🔍 Descrição
Durante o processo de validação, o servidor LLM perde conexão intermitentemente, resultando em fallback para decisões de validação com confidence 0%. O servidor está ativo e saudável (conforme health check), mas falha ao responder às requisições de validação no endpoint `/validate`.

## 📂 Massa de Dados
- **Arquivo:** data/input/sample.csv
- **Tamanho:** 5 registros (pequeno)
- **Características:** Dados simples com campos básicos (id, name, email, age, status)

## 🔄 Passos para Reproduzir
1. Verificar que o servidor LLM está ativo: `curl http://localhost:8000/health` (✅ retorna healthy)
2. Executar comando: `npm run dev validate -- --input data/input/sample.csv --config config/sample-validation.yaml --output tests/test-sample-tc001 --verbose --max-rows 5`
3. Observar que o processo inicia corretamente
4. Durante a validação, as requisições para `/validate` começam a falhar

## 📋 Resultado Esperado
- Servidor LLM deveria responder consistentemente às requisições de validação
- Confidence scores deveriam ser > 0% para dados válidos
- Não deveria haver fallbacks devido a falhas de conexão

## ❌ Resultado Atual
- Health check inicial: ✅ Servidor LLM encontrado e pronto!
- Primeira validação: ✅ Sucesso (confidence > 0%)
- Validações subsequentes: ❌ Falharam com "fetch failed"
- Todas as validações terminaram em fallback com confidence 0%

## 📝 Logs/Evidências
```
[32minfo[39m: ✅ Servidor LLM encontrado e pronto! {"loadTime":3.9982874393463135,"modelLoaded":true,"requestCount":0,"responseTime":"174ms","service":"datahawk","status":"healthy"}

[32minfo[39m: ✅ Validação LLM bem-sucedida {"confidence":0.95,"csvValuePreview":"John Doe","fieldName":"name","match":true,"requestId":1,"responseTime":"4901ms","service":"datahawk"}

[33mwarn[39m: ⚠️ Requisição de validação falhou (tentativa 1/3) {"attempt":1,"error":"Servidor LLM não está respondendo aos health checks: fetch failed","errorType":"Error","fieldName":"name"}

[31merror[39m: ❌ Todas as tentativas de validação falharam {"error":{"attempts":3,"error":"Servidor LLM não está respondendo aos health checks: fetch failed"}}
```

## 💡 Possíveis Causas
1. **Timeout do servidor LLM:** O servidor pode estar processando requisições muito lentamente
2. **Limite de conexões simultâneas:** O servidor pode ter limite de conexões concorrentes
3. **Memory/CPU overload:** O modelo pode estar sobrecarregando o sistema
4. **Problema na configuração de health check:** Lógica de verificação pode estar incorreta
5. **Race condition:** Múltiplas requisições simultâneas podem estar causando conflito

## 🔧 Solução Proposta
1. **Imediata:** Aumentar timeouts de conexão e implementar retry com backoff exponencial
2. **Intermediária:** Implementar queue de requisições para evitar sobrecarga
3. **Longo prazo:** Monitoramento contínuo da saúde do servidor LLM

## 📊 Impacto
- **Funcionalidade:** Alta - impossibilita validação adequada dos dados
- **Confiabilidade:** Crítica - confidence 0% em todas as validações após a primeira
- **Performance:** Media - processo ainda completa, mas com qualidade ruim

## 📎 Anexos
- Logs completos em: `tests/test-sample-tc001/`
- Relatório gerado: `tests/test-sample-tc001/datahawk-report-2025-07-21T01-29-25.json`
- Evidências em: `tests/test-sample-tc001/evidence/`