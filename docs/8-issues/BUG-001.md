# BUG-001: Servidor LLM perde conexÃ£o durante validaÃ§Ã£o

## ğŸ“‹ InformaÃ§Ãµes BÃ¡sicas
- **ID:** BUG-001
- **Data:** 2025-07-21
- **Severidade:** High
- **Status:** Open

## ğŸ” DescriÃ§Ã£o
Durante o processo de validaÃ§Ã£o, o servidor LLM perde conexÃ£o intermitentemente, resultando em fallback para decisÃµes de validaÃ§Ã£o com confidence 0%. O servidor estÃ¡ ativo e saudÃ¡vel (conforme health check), mas falha ao responder Ã s requisiÃ§Ãµes de validaÃ§Ã£o no endpoint `/validate`.

## ğŸ“‚ Massa de Dados
- **Arquivo:** data/input/sample.csv
- **Tamanho:** 5 registros (pequeno)
- **CaracterÃ­sticas:** Dados simples com campos bÃ¡sicos (id, name, email, age, status)

## ğŸ”„ Passos para Reproduzir
1. Verificar que o servidor LLM estÃ¡ ativo: `curl http://localhost:8000/health` (âœ… retorna healthy)
2. Executar comando: `npm run dev validate -- --input data/input/sample.csv --config config/sample-validation.yaml --output tests/test-sample-tc001 --verbose --max-rows 5`
3. Observar que o processo inicia corretamente
4. Durante a validaÃ§Ã£o, as requisiÃ§Ãµes para `/validate` comeÃ§am a falhar

## ğŸ“‹ Resultado Esperado
- Servidor LLM deveria responder consistentemente Ã s requisiÃ§Ãµes de validaÃ§Ã£o
- Confidence scores deveriam ser > 0% para dados vÃ¡lidos
- NÃ£o deveria haver fallbacks devido a falhas de conexÃ£o

## âŒ Resultado Atual
- Health check inicial: âœ… Servidor LLM encontrado e pronto!
- Primeira validaÃ§Ã£o: âœ… Sucesso (confidence > 0%)
- ValidaÃ§Ãµes subsequentes: âŒ Falharam com "fetch failed"
- Todas as validaÃ§Ãµes terminaram em fallback com confidence 0%

## ğŸ“ Logs/EvidÃªncias
```
[32minfo[39m: âœ… Servidor LLM encontrado e pronto! {"loadTime":3.9982874393463135,"modelLoaded":true,"requestCount":0,"responseTime":"174ms","service":"datahawk","status":"healthy"}

[32minfo[39m: âœ… ValidaÃ§Ã£o LLM bem-sucedida {"confidence":0.95,"csvValuePreview":"John Doe","fieldName":"name","match":true,"requestId":1,"responseTime":"4901ms","service":"datahawk"}

[33mwarn[39m: âš ï¸ RequisiÃ§Ã£o de validaÃ§Ã£o falhou (tentativa 1/3) {"attempt":1,"error":"Servidor LLM nÃ£o estÃ¡ respondendo aos health checks: fetch failed","errorType":"Error","fieldName":"name"}

[31merror[39m: âŒ Todas as tentativas de validaÃ§Ã£o falharam {"error":{"attempts":3,"error":"Servidor LLM nÃ£o estÃ¡ respondendo aos health checks: fetch failed"}}
```

## ğŸ’¡ PossÃ­veis Causas
1. **Timeout do servidor LLM:** O servidor pode estar processando requisiÃ§Ãµes muito lentamente
2. **Limite de conexÃµes simultÃ¢neas:** O servidor pode ter limite de conexÃµes concorrentes
3. **Memory/CPU overload:** O modelo pode estar sobrecarregando o sistema
4. **Problema na configuraÃ§Ã£o de health check:** LÃ³gica de verificaÃ§Ã£o pode estar incorreta
5. **Race condition:** MÃºltiplas requisiÃ§Ãµes simultÃ¢neas podem estar causando conflito

## ğŸ”§ SoluÃ§Ã£o Proposta
1. **Imediata:** Aumentar timeouts de conexÃ£o e implementar retry com backoff exponencial
2. **IntermediÃ¡ria:** Implementar queue de requisiÃ§Ãµes para evitar sobrecarga
3. **Longo prazo:** Monitoramento contÃ­nuo da saÃºde do servidor LLM

## ğŸ“Š Impacto
- **Funcionalidade:** Alta - impossibilita validaÃ§Ã£o adequada dos dados
- **Confiabilidade:** CrÃ­tica - confidence 0% em todas as validaÃ§Ãµes apÃ³s a primeira
- **Performance:** Media - processo ainda completa, mas com qualidade ruim

## ğŸ“ Anexos
- Logs completos em: `tests/test-sample-tc001/`
- RelatÃ³rio gerado: `tests/test-sample-tc001/datahawk-report-2025-07-21T01-29-25.json`
- EvidÃªncias em: `tests/test-sample-tc001/evidence/`