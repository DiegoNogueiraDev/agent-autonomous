# BUG-002: LLM utilizando fallback em vez de anÃ¡lise semÃ¢ntica

## ğŸ“‹ InformaÃ§Ãµes BÃ¡sicas
- **ID:** BUG-002
- **Data:** 2025-07-21
- **Severidade:** Medium
- **Status:** Open

## ğŸ” DescriÃ§Ã£o
O servidor LLM estÃ¡ retornando respostas de "ComparaÃ§Ã£o de string fallback" em vez de realizar anÃ¡lise semÃ¢ntica adequada dos dados. Isso indica que o modelo nÃ£o estÃ¡ sendo utilizado corretamente para validaÃ§Ã£o inteligente.

## ğŸ“‚ Massa de Dados
- **Teste 1:** csv_value="John Doe", web_value="Example Domain"
- **Teste 2:** csv_value="Example Domain", web_value="Example Domain"

## ğŸ”„ Passos para Reproduzir
1. Executar: `curl -X POST http://localhost:8000/validate -H "Content-Type: application/json" -d '{"csv_value": "John Doe", "web_value": "Example Domain", "field_type": "string", "field_name": "name"}'`
2. Observar resposta com reasoning: "ComparaÃ§Ã£o de string fallback"

## ğŸ“‹ Resultado Esperado
- LLM deveria fazer anÃ¡lise semÃ¢ntica dos valores
- Reasoning deveria explicar a lÃ³gica da comparaÃ§Ã£o
- Deveria considerar contexto e significado dos campos

## âŒ Resultado Atual
- **Teste 1:** confidence=0.5, match=false, reasoning="ComparaÃ§Ã£o de string fallback"
- **Teste 2:** confidence=1.0, match=true, reasoning="ComparaÃ§Ã£o de string fallback"
- Ambos os casos utilizam fallback em vez de LLM

## ğŸ“ Logs/EvidÃªncias
```json
// Teste 1 - Valores diferentes
{
  "confidence": 0.5,
  "match": false,
  "processing_time": 6.443647146224976,
  "reasoning": "ComparaÃ§Ã£o de string fallback",
  "tokens": 1
}

// Teste 2 - Valores iguais  
{
  "confidence": 1.0,
  "match": true,
  "processing_time": 6.719940423965454,
  "reasoning": "ComparaÃ§Ã£o de string fallback",
  "tokens": 1
}
```

## ğŸ’¡ PossÃ­veis Causas
1. **ConfiguraÃ§Ã£o incorreta do modelo:** LLM pode nÃ£o estar carregado adequadamente
2. **Prompt inadequado:** Sistema prompt pode nÃ£o estar direcionando para anÃ¡lise semÃ¢ntica
3. **Fallback ativado incorretamente:** LÃ³gica pode estar forÃ§ando fallback
4. **Timeout muito baixo:** LLM pode nÃ£o ter tempo suficiente para processar
5. **Problema na API do modelo:** Endpoint /validate pode ter bug interno

## ğŸ”§ SoluÃ§Ã£o Proposta
1. **Verificar configuraÃ§Ã£o do modelo:** Confirmar que modelo estÃ¡ carregado corretamente
2. **Revisar system prompt:** Garantir que instruÃ§Ãµes sÃ£o claras para anÃ¡lise semÃ¢ntica
3. **Aumentar timeout:** Dar mais tempo para processamento do LLM
4. **Debug do endpoint:** Adicionar logs detalhados no servidor LLM

## ğŸ“Š Impacto
- **Funcionalidade:** Media - sistema funciona mas sem inteligÃªncia
- **Qualidade:** Alta - validaÃ§Ãµes sÃ£o apenas comparaÃ§Ãµes simples de string
- **Performance:** Baixa - nÃ£o aproveita capacidade do LLM

## ğŸ”— Relacionado
- **BUG-001:** Problemas de conectividade LLM podem agravar este issue