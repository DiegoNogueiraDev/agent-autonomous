# DataHawk LLM Server - VersÃ£o Modular

## ğŸ“ Estrutura do Projeto

```
src/llm_server/
â”œâ”€â”€ __init__.py          # Pacote principal
â”œâ”€â”€ main.py             # Ponto de entrada
â”œâ”€â”€ logs/               # Sistema de logging
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logger.py       # ConfiguraÃ§Ã£o de logs
â”œâ”€â”€ core/               # Funcionalidade principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ health_monitor.py  # Monitoramento de saÃºde
â”‚   â””â”€â”€ model_manager.py   # Gerenciamento do modelo
â”œâ”€â”€ models/             # Modelos de dados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ responses.py    # Estruturas de resposta
â”œâ”€â”€ api/                # Endpoints HTTP
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ routes.py       # Rotas Flask
â”œâ”€â”€ utils/              # UtilitÃ¡rios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ formatters.py   # FunÃ§Ãµes de formataÃ§Ã£o
â”‚   â””â”€â”€ signals.py      # Handlers de sinais
â””â”€â”€ README.md          # Este arquivo
```

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Usando o script modular
```bash
python llm-server-modular.py
```

### OpÃ§Ã£o 2: Usando o mÃ³dulo diretamente
```bash
python -m llm_server.main
```

### OpÃ§Ã£o 3: Instalando como pacote
```bash
pip install -e .
python -c "from llm_server.main import main; main()"
```

## ğŸ“¡ Endpoints DisponÃ­veis

- **GET /health** - VerificaÃ§Ã£o de saÃºde do servidor
- **POST /load** - Carregar modelo
- **POST /generate** - Gerar resposta (compatÃ­vel llama.cpp)
- **POST /completion** - Completion (compatÃ­vel llama.cpp)
- **POST /validate** - ValidaÃ§Ã£o especÃ­fica de dados

## ğŸ§ª Exemplos de Uso

### Health Check
```bash
curl http://localhost:8000/health
```

### Carregar Modelo
```bash
curl -X POST http://localhost:8000/load \
  -H "Content-Type: application/json" \
  -d '{"model_path": "./models/llama3-8b-instruct.Q4_K_M.gguf"}'
```

### Gerar Resposta
```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Qual Ã© a capital do Brasil?", "max_tokens": 100}'
```

### Validar Dados
```bash
curl -X POST http://localhost:8000/validate \
  -H "Content-Type: application/json" \
  -d '{
    "csv_value": "SÃ£o Paulo",
    "web_value": "Sao Paulo",
    "field_type": "string",
    "field_name": "cidade"
  }'
```

## ğŸ“Š Logs

Os logs sÃ£o salvos em:
- `logs/llm-server.log` - Log geral
- `logs/llm-server-errors.log` - Apenas erros
- `logs/llm-server-metrics.log` - MÃ©tricas de performance

## ğŸ—ï¸ Arquitetura

### PrincÃ­pios de Design
- **Single Responsibility**: Cada mÃ³dulo tem uma responsabilidade Ãºnica
- **Clean Architecture**: SeparaÃ§Ã£o clara entre camadas
- **Dependency Injection**: Facilita testes e manutenÃ§Ã£o
- **Logging Centralizado**: Sistema robusto de logs

### Camadas
1. **API Layer** (`api/`): Endpoints HTTP e validaÃ§Ã£o de entrada
2. **Core Layer** (`core/`): LÃ³gica de negÃ³cio principal
3. **Models Layer** (`models/`): Estruturas de dados
4. **Utils Layer** (`utils/`): FunÃ§Ãµes auxiliares
5. **Logs Layer** (`logs/`): Sistema de logging

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente
- `LLM_MODEL_PATH`: Caminho do modelo (padrÃ£o: ./models/llama3-8b-instruct.Q4_K_M.gguf)
- `LLM_HOST`: Host do servidor (padrÃ£o: 127.0.0.1)
- `LLM_PORT`: Porta do servidor (padrÃ£o: 8000)

### ParÃ¢metros do Modelo
- `n_ctx`: Tamanho do contexto (adaptativo baseado no tamanho do modelo)
- `n_threads`: NÃºmero de threads (CPU count ou 4)
- `n_batch`: Tamanho do batch (512)
- `temperature`: Temperatura padrÃ£o (0.1)

## ğŸ§ª Testes

Para executar testes bÃ¡sicos:
```bash
# Testar health check
curl http://localhost:8000/health

# Testar com modelo carregado
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello"}'
```

## ğŸ”„ MigraÃ§Ã£o da VersÃ£o Original

A versÃ£o modular mantÃ©m 100% de compatibilidade com a API original. Todos os endpoints e formatos de resposta sÃ£o idÃªnticos.

### DiferenÃ§as Principais
- CÃ³digo dividido em mÃ³dulos coesos
- Melhor organizaÃ§Ã£o e manutenibilidade
- Sistema de logging mais robusto
- Facilita testes unitÃ¡rios
- PreparaÃ§Ã£o para futuras extensÃµes
